{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e46048-0470-41a6-9023-6a5c2fc36577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from  helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ca12b-f76d-403e-92f6-b13ec723fd37",
   "metadata": {},
   "source": [
    "Fetch data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9f2f999-deba-4602-9a45-e94807f81216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#House sale price and other sale details downloaded from https://www.gov.uk/government/statistical-data-sets/price-paid-data-downloads\n",
    "#Column data from https://www.gov.uk/guidance/about-the-price-paid-data#explanations-of-column-headers-in-the-ppd\n",
    "#2024 data\n",
    "house_2024 = pd.read_csv('http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-2024.csv')\n",
    "house_2024.columns = ['Ref_no','Price','Date','Postcode','Type','New','Tenure','Address_1','Address_2','Street','Locality','City','District','County','PPD_category','Record_Status']\n",
    "#2023 data\n",
    "house_2023= pd.read_csv('http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-2023.csv')\n",
    "house_2023.columns = ['Ref_no','Price','Date','Postcode','Type','New','Tenure','Address_1','Address_2','Street','Locality','City','District','County','PPD_category','Record_Status']\n",
    "#2022 data\n",
    "house_2022 = pd.read_csv('http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-2022.csv')\n",
    "house_2022.columns = ['Ref_no','Price','Date','Postcode','Type','New','Tenure','Address_1','Address_2','Street','Locality','City','District','County','PPD_category','Record_Status']\n",
    "\n",
    "#files linking lsoa, msoa and ltla codes to postcodes\n",
    "#Needed to join cencus data to postcode\n",
    "#Files from https://geoportal.statistics.gov.uk/datasets/c4f84c38814d4b82aa4760ade686c3cc/about\n",
    "lsoa_msoa_raw = pd.read_csv('https://www.arcgis.com/sharing/rest/content/items/c4f84c38814d4b82aa4760ade686c3cc/data',compression='zip',dtype=str)\n",
    "#From https://geoportal.statistics.gov.uk/datasets/c4f84c38814d4b82aa4760ade686c3cc/about\n",
    "ltla_raw = pd.read_csv('https://www.arcgis.com/sharing/rest/content/items/bc8f6d1f6ee64111b6a59b22c6605f3b/data',compression='zip',dtype=str)\n",
    "\n",
    "#Latitude and longitude data for each postcode\n",
    "#postcode location from file downlaoded from https://www.freemaptools.com/download-uk-postcode-lat-lng.htm\n",
    "postcode_lat_lon_raw = pd.read_csv('https://data.freemaptools.com/download/full-uk-postcodes/ukpostcodes.zip',compression='zip',dtype=str)\n",
    "\n",
    "#Demographics data\n",
    "#downloaded from https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/lowersuperoutputareamidyearpopulationestimates\n",
    "#preprocessed in excel and saved as csv\n",
    "demographics = pd.read_csv('input_files/demographics.csv')\n",
    "\n",
    "#Average Commute \n",
    "#Downloaded from https://www.ons.gov.uk/datasets/TS058/editions/2021/versions/4/filter-outputs/1242b10f-061d-4db7-9e69-ab1f2036e00f#get-data\n",
    "#preprocessed in excel and saved as csv\n",
    "commute = pd.read_csv('input_files/commute.csv')\n",
    "\n",
    "#2023 wage data downloaded from https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/smallareaincomeestimatesformiddlelayersuperoutputareasenglandandwales\n",
    "#excel converted to csv\n",
    "wages = pd.read_csv('input_files/wages.csv')\n",
    "\n",
    "#rural/urban\n",
    "#excel file from https://www.ons.gov.uk/methodology/geography/geographicalproducts/ruralurbanclassifications/2021ruralurbanclassification\n",
    "#table 1b converted to csv using excel\n",
    "rural_urban = pd.read_csv('input_files/rural_urban.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1998a9cf-65ce-4726-a39d-b032fcdea562",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frames = [house_2022, house_2023, house_2024]\n",
    "train_house = pd.concat(train_frames)\n",
    "train_house.drop(['Ref_no','PPD_category','Record_Status'], axis=1, inplace=True)\n",
    "train_house.reset_index(drop=True, inplace=True)\n",
    "train_house.to_csv('train_house.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb085f1c-eef8-4736-8cdc-20ddbf343aec",
   "metadata": {},
   "source": [
    "A: Fill missing postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e668fc83-c7e3-4eb9-a8d2-6e7b7235fa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7794 missing postcodes in train_house\n"
     ]
    }
   ],
   "source": [
    "print(f'{sum(train_house['Postcode'].isnull())} missing postcodes in train_house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8acc2c-804a-4134-a28e-880dff5f5564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_house_1 = train_house.copy()\n",
    "fill_empty_postcode(train_house_1, train_house)\n",
    "train_house_1.to_csv('train_house_1.csv', index=False)\n",
    "\n",
    "#Takes a long time to run. Progress will be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0358686f-7b03-44b4-b1cd-e9717bfb6214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing postcodes in train_house_1\n"
     ]
    }
   ],
   "source": [
    "print(f'{sum(train_house_1['Postcode'].isnull())} missing postcodes in train_house_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08893abc-e46f-4b3f-99c7-dfd65008da53",
   "metadata": {},
   "source": [
    "B: Sample unique postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1afbacb2-b07c-4f67-b272-eca1b49d19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes = train_house_1['Postcode'].unique()\n",
    "\n",
    "train_postcode_1 = pd.DataFrame({'postcode':postcodes})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa4d351-d58c-4c90-a6c8-c1b47b5ea42e",
   "metadata": {},
   "source": [
    "C: Join LTLA, LSOA, MSOA, Latitude and Longitude on postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d80ddff-8cc9-4714-9f83-d3885bb9d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_postcode_2 = train_postcode_1.copy()\n",
    "\n",
    "lsoa_msoa = lsoa_msoa_raw[['pcds', 'lsoa21cd', 'msoa21cd']].set_index('pcds')\n",
    "ltla = ltla_raw[['pcds', 'ltla22cd']].set_index('pcds')\n",
    "lat_lon = postcode_lat_lon_raw.drop('id', axis=1).set_index('postcode')\n",
    "\n",
    "train_postcode_2 = train_postcode_2.join(lsoa_msoa, on='postcode')\n",
    "train_postcode_2 = train_postcode_2.join(ltla, on='postcode')\n",
    "train_postcode_2 = train_postcode_2.join(lat_lon, on='postcode')\n",
    "\n",
    "train_postcode_2.rename({'lsoa21cd':'lsoa', 'msoa21cd':'msoa', 'ltla22cd':'ltla'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39beba3-1570-4df5-83f0-4f244daa8bf8",
   "metadata": {},
   "source": [
    "D: Fill missing LTLA, LSOA, MSOA, Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fbbf46d-7e5d-43b6-975d-ddb82022c794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 missing lsoa\n",
      "86 missing msoa\n",
      "4294 missing ltla\n",
      "2251 missing latitude\n",
      "2251 missing longitude\n"
     ]
    }
   ],
   "source": [
    "print(f'{sum(train_postcode_2['lsoa'].isna())} missing lsoa')\n",
    "print(f'{sum(train_postcode_2['msoa'].isna())} missing msoa')\n",
    "print(f'{sum(train_postcode_2['ltla'].isna())} missing ltla')\n",
    "print(f'{sum(train_postcode_2['latitude'].isna())} missing latitude')\n",
    "print(f'{sum(train_postcode_2['longitude'].isna())} missing longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8adbaba-e2c8-4549-bdf1-af794ec2ed9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_postcode_3 = train_postcode_2.copy()\n",
    "\n",
    "fill_missing_ltla(train_postcode_3, ltla_raw)\n",
    "fill_missing_lsoa(train_postcode_3, lsoa_msoa_raw)\n",
    "fill_missing_lat_lon(train_postcode_3, postcode_lat_lon_raw)\n",
    "\n",
    "train_postcode_3.to_csv('train_postcode_3.csv', index=False)\n",
    "\n",
    "#Takes time to run. Will print progress to console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db0d5200-b275-4fa5-884f-4badf62a9849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing lsoa\n",
      "0 missing msoa\n",
      "0 missing ltla\n",
      "0 missing latitude\n",
      "0 missing longitude\n"
     ]
    }
   ],
   "source": [
    "print(f'{sum(train_postcode_3['lsoa'].isna())} missing lsoa')\n",
    "print(f'{sum(train_postcode_3['msoa'].isna())} missing msoa')\n",
    "print(f'{sum(train_postcode_3['ltla'].isna())} missing ltla')\n",
    "print(f'{sum(train_postcode_3['latitude'].isna())} missing latitude')\n",
    "print(f'{sum(train_postcode_3['longitude'].isna())} missing longitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81633645-f03e-4f57-865e-fb55fbc27aee",
   "metadata": {},
   "source": [
    "E: Join additional postcode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8677bf82-5baf-4e04-9821-40385dd558e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_postcode_3 = pd.read_csv('train_postcode_3.csv')\n",
    "train_postcode_4 = train_postcode_3.copy()\n",
    "train_postcode_4 = train_postcode_4.join(demographics.set_index('LSOA 2021 Code'), on='lsoa')\n",
    "train_postcode_4 = train_postcode_4.join(commute.set_index('LTLA'), on='ltla')\n",
    "train_postcode_4 = train_postcode_4.join(wages.set_index('msoa'), on='msoa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4f03f-ed19-4efc-9cf5-4afd1224225d",
   "metadata": {},
   "source": [
    "F: Calculate additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdd360-d2ad-4aa1-804a-bceaf92f1b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_postcode_5 = train_postcode_4.copy()\n",
    "\n",
    "#England or wales\n",
    "#Determine using first letter of LTLA code\n",
    "train_postcode_5['Eng_Wal'] = train_postcode_5['ltla'].str[0]\n",
    "train_postcode_5['Eng_Wal'] = train_postcode_5['Eng_Wal'].map({'E':'England','W':'Wales'})\n",
    "\n",
    "#Distance from London\n",
    "#getting the distance from the centre of london (chosen to be Big Ben)\n",
    "#This block takes a short time to run, progress will be printed\n",
    "train_postcode_5['London_distance'] = london_distance(train_postcode_5['latitude'], train_postcode_5['longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc47397-eced-4fa0-b813-c0ca10041ed7",
   "metadata": {},
   "source": [
    "G: Join postcode data to main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f45971f-3c69-4d3b-82cb-aa3f5a142394",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_house_2 = train_house_1.join(train_postcode_5.set_index('postcode'), on='Postcode')\n",
    "train_house_2.to_csv('train_house_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6398e-aa4f-43b6-b60f-59608f7b2344",
   "metadata": {},
   "source": [
    "H: Calculate helper metrics for both train and test frames (training data only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5887ab72-d1e6-4124-b758-3c66e4a2c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_house_2 = pd.read_csv('train_house_2.csv')\n",
    "\n",
    "#Earliest date in the training data\n",
    "earliest_date = pd.DataFrame({'earliest_date':pd.to_datetime([train_house_2['Date'].min()])})\n",
    "earliest_date.to_csv('helper_metrics/train_earliest_date.csv', index=False)\n",
    "\n",
    "#Number of listings for each lsoa code, to calculate per capita listings\n",
    "lsoa_count = pd.DataFrame(train_house_2['lsoa'].value_counts())\n",
    "counts = train_postcode_5[['lsoa','lsoa population']].drop_duplicates()\n",
    "lsoa_count = lsoa_count.join(counts.set_index('lsoa'))\n",
    "lsoa_count['listings_per_capita'] = lsoa_count['count']/lsoa_count['lsoa population']\n",
    "lsoa_count.drop(['count','lsoa population'], axis=1, inplace=True)\n",
    "lsoa_count = lsoa_count.round(4)\n",
    "lsoa_count.to_csv('helper_metrics/train_lsoa_count.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084c68b8-2e7d-4b65-a8b0-ec243fd70cba",
   "metadata": {},
   "source": [
    "I: Calculate additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "05491a5f-c42d-434c-b31d-335f931fde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_house_2 = pd.read_csv('train_house_2.csv')\n",
    "\n",
    "#per capita listings by lsoa area\n",
    "lsoa_count = pd.read_csv('helper_metrics/train_lsoa_count.csv')\n",
    "train_house_3 = train_house_2.join(lsoa_count.set_index('lsoa'), on='lsoa')\n",
    "\n",
    "#days since first listing in train df\n",
    "first_date_df = pd.read_csv('helper_metrics/train_earliest_date.csv')\n",
    "first_date = pd.to_datetime(first_date_df.iloc[0,0])\n",
    "days_since_first = (pd.to_datetime(train_house_3['Date']) - first_date).dt.days\n",
    "train_house_3['days_since_first'] = days_since_first\n",
    "\n",
    "#Day of hte year encoded as sine and cosine wave\n",
    "day_of_year = pd.to_datetime(train_house_3['Date']).dt.dayofyear\n",
    "train_house_3['sine_day'] = np.sin(day_of_year*2*np.pi/365)\n",
    "train_house_3['cosine_day'] = np.cos(day_of_year*2*np.pi/365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe480ba-233d-4556-8c13-6796c7ab8653",
   "metadata": {},
   "source": [
    "J: Remove unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ffc0c28e-3264-41e2-9836-ecdf2786ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_house_4 = train_house_3.drop(['Postcode', 'Date', 'Address_1', 'Address_2', 'Street', 'Locality', 'City', 'District',\n",
    "                                    'County', 'msoa', 'lsoa', 'ltla', 'lsoa population'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2fda89-a0ff-4d6c-aabe-6061e260a60a",
   "metadata": {},
   "source": [
    "K: Investigate and fix missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bb5e7318-dc64-4172-98f4-8801113ae7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2832895 entries, 0 to 2832894\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   Price                2832895 non-null  int64  \n",
      " 1   Type                 2832895 non-null  object \n",
      " 2   New                  2832895 non-null  object \n",
      " 3   Tenure               2832895 non-null  object \n",
      " 4   latitude             2832895 non-null  float64\n",
      " 5   longitude            2832895 non-null  float64\n",
      " 6   gender_ratio         2832894 non-null  float64\n",
      " 7   child_ratio          2832894 non-null  float64\n",
      " 8   elderly_ratio        2832894 non-null  float64\n",
      " 9   commute_distance     2832894 non-null  float64\n",
      " 10  Income               2832894 non-null  float64\n",
      " 11  Eng_Wal              2832894 non-null  object \n",
      " 12  London_distance      2832895 non-null  float64\n",
      " 13  listings_per_capita  2832894 non-null  float64\n",
      " 14  days_since_first     2832895 non-null  int64  \n",
      " 15  sine_day             2832895 non-null  float64\n",
      " 16  cosine_day           2832895 non-null  float64\n",
      "dtypes: float64(11), int64(2), object(4)\n",
      "memory usage: 367.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_house_4.info(show_counts=True)\n",
    "#one item seems to be missing postcode related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b0140389-0182-4a34-b327-08f7b7f3456b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Type</th>\n",
       "      <th>New</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>gender_ratio</th>\n",
       "      <th>child_ratio</th>\n",
       "      <th>elderly_ratio</th>\n",
       "      <th>commute_distance</th>\n",
       "      <th>Income</th>\n",
       "      <th>Eng_Wal</th>\n",
       "      <th>London_distance</th>\n",
       "      <th>listings_per_capita</th>\n",
       "      <th>days_since_first</th>\n",
       "      <th>sine_day</th>\n",
       "      <th>cosine_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1820838</th>\n",
       "      <td>490000</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>56.208453</td>\n",
       "      <td>-3.200442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560.875208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>709</td>\n",
       "      <td>-0.337523</td>\n",
       "      <td>0.941317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Price Type New Tenure   latitude  longitude  gender_ratio  \\\n",
       "1820838  490000    F   N      L  56.208453  -3.200442           NaN   \n",
       "\n",
       "         child_ratio  elderly_ratio  commute_distance  Income Eng_Wal  \\\n",
       "1820838          NaN            NaN               NaN     NaN     NaN   \n",
       "\n",
       "         London_distance  listings_per_capita  days_since_first  sine_day  \\\n",
       "1820838       560.875208                  NaN               709 -0.337523   \n",
       "\n",
       "         cosine_day  \n",
       "1820838    0.941317  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_house_4[train_house_4['gender_ratio'].isna()]\n",
    "#Latitude/longitude (56.208453,-3.200442) is in scotland. \n",
    "#Looks like this was included in the england/Wales data by accident\n",
    "#Should be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "48fc415b-573e-4470-8ab3-90bd7e3e00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_house_final = train_house_4.dropna()\n",
    "train_house_final.to_csv('train_house_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
